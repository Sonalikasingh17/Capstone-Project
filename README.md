# ğŸš€ Capstone Project â€“ End-to-End MLOps Pipeline

![Python](https://img.shields.io/badge/Python-3.10-blue?logo=python)
![MLflow](https://img.shields.io/badge/MLflow-Tracking-orange?logo=mlflow)
![AWS](https://img.shields.io/badge/AWS-EKS%20|%20S3%20|%20ECR-orange?logo=amazonaws)
![Docker](https://img.shields.io/badge/Docker-Containerization-blue?logo=docker)
![GitHub Actions](https://img.shields.io/badge/CI/CD-GitHub%20Actions-2088FF?logo=githubactions)
![Prometheus](https://img.shields.io/badge/Prometheus-Monitoring-red?logo=prometheus)
![Grafana](https://img.shields.io/badge/Grafana-Dashboard-orange?logo=grafana)

> ğŸ§  A complete **Machine Learning Operations (MLOps)** pipeline â€” from local development to cloud deployment and monitoring.

---

## ğŸ§© Project Overview

This Capstone Project automates the **end-to-end ML lifecycle** using modern DevOps and MLOps tools.  
Youâ€™ll learn how to build, version, deploy, and monitor a machine learning model in production ğŸŒâš™ï¸

**Key Features:**
- ğŸ§® Data pipeline: Ingestion â†’ Preprocessing â†’ Feature Engineering  
- ğŸ¤– Model lifecycle: Training â†’ Evaluation â†’ Registration  
- ğŸ“Š Experiment tracking using **MLflow (Dagshub)**  
- ğŸ’¾ Dataset versioning using **DVC + AWS S3**  
- ğŸ³ Containerization using **Docker**  
- ğŸ” Deployment automation using **GitHub Actions + AWS ECR + EKS**  
- ğŸ“ˆ Monitoring using **Prometheus + Grafana**

---

## ğŸ—ï¸ Project Structure


Capstone-Project/
â”‚
â”œâ”€â”€ src/
â”‚ â”œâ”€â”€ logger/
â”‚ â”œâ”€â”€ data_ingestion.py
â”‚ â”œâ”€â”€ data_preprocessing.py
â”‚ â”œâ”€â”€ feature_engineering.py
â”‚ â”œâ”€â”€ model_building.py
â”‚ â”œâ”€â”€ model_evaluation.py
â”‚ â”œâ”€â”€ register_model.py
â”‚
â”œâ”€â”€ flask_app/
â”‚ â”œâ”€â”€ app.py
â”‚ â”œâ”€â”€ templates/
â”‚ â”œâ”€â”€ static/
â”‚
â”œâ”€â”€ tests/
â”œâ”€â”€ scripts/
â”œâ”€â”€ params.yaml
â”œâ”€â”€ dvc.yaml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ .github/workflows/ci.yaml
â””â”€â”€ README.md

---

## âš™ï¸ Tech Stack

| Category | Tools |
|-----------|--------|
| ğŸ§  **ML Frameworks** | Scikit-learn, Pandas, NumPy |
| ğŸ’¾ **Versioning & Tracking** | DVC, MLflow, Dagshub |
| ğŸ³ **Containerization** | Docker |
| â˜ï¸ **Cloud Services** | AWS S3, ECR, EKS |
| ğŸ” **Automation** | GitHub Actions |
| ğŸ“Š **Monitoring** | Prometheus, Grafana |
| ğŸ§° **Environment** | Conda, Python 3.10 |

---

<details>
<summary>ğŸ§° <b>1ï¸âƒ£ Project Setup</b></summary>

```bash
# Create virtual environment
conda create -n atlas python=3.10
conda activate atlas

# Install template
pip install cookiecutter
cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science

# Rename and initialize repo
mv src.models src.model
git add .
git commit -m "Initial setup"
git push
```

<details> 

<details> <summary>ğŸ“Š <b>2ï¸âƒ£ Setup MLflow Tracking (Dagshub)</b></summary>

Go to Dagshub Dashboard

Create a new repo and connect your GitHub repository

Copy the MLflow tracking URL & integrate it into your notebooks

Install dependencies
```bash
pip install dagshub mlflow
```

<details> 
