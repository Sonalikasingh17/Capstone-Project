{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "import mlflow.sklearn\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This is what I was expecting when star trek DS...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>The Salena Incident is set in Arizona where si...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>Twenty five years ago, I showed this film in s...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>601</th>\n",
       "      <td>I suppose if you like pure action... you'll fi...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>I found the pace to be glacial and the origina...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "29   This is what I was expecting when star trek DS...  positive\n",
       "160  The Salena Incident is set in Arizona where si...  negative\n",
       "590  Twenty five years ago, I showed this film in s...  positive\n",
       "601  I suppose if you like pure action... you'll fi...  negative\n",
       "376  I found the pace to be glacial and the origina...  negative"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('IMDB.csv')\n",
    "df = df.sample(500)\n",
    "df.to_csv('data.csv', index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "\n",
    "# Define text preprocessing functions\n",
    "def lemmatization(text):\n",
    "    \"\"\"Lemmatize the text.\"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = text.split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    \"\"\"Remove stop words from the text.\"\"\"\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    text = [word for word in str(text).split() if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_numbers(text):\n",
    "    \"\"\"Remove numbers from the text.\"\"\"\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "def lower_case(text):\n",
    "    \"\"\"Convert text to lower case.\"\"\"\n",
    "    text = text.split()\n",
    "    text = [word.lower() for word in text]\n",
    "    return \" \".join(text)\n",
    "\n",
    "def removing_punctuations(text):\n",
    "    \"\"\"Remove punctuations from the text.\"\"\"\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), ' ', text)\n",
    "    text = text.replace('؛', \"\")\n",
    "    text = re.sub('\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def removing_urls(text):\n",
    "    \"\"\"Remove URLs from the text.\"\"\"\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "def normalize_text(df):\n",
    "    \"\"\"Normalize the text data.\"\"\"\n",
    "    try:\n",
    "        df['review'] = df['review'].apply(lower_case)\n",
    "        df['review'] = df['review'].apply(remove_stop_words)\n",
    "        df['review'] = df['review'].apply(removing_numbers)\n",
    "        df['review'] = df['review'].apply(removing_punctuations)\n",
    "        df['review'] = df['review'].apply(removing_urls)\n",
    "        df['review'] = df['review'].apply(lemmatization)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f'Error during text normalization: {e}')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>hugh ed harris hotshot bachelor senator determ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>labor love frame picture perfect grab you shee...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>now like sci fi cartoon however robotboy appea...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>and episode really hoping not mention canceled...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>ann margret best job ever done history film ma...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review sentiment\n",
       "71   hugh ed harris hotshot bachelor senator determ...  positive\n",
       "775  labor love frame picture perfect grab you shee...  positive\n",
       "416  now like sci fi cartoon however robotboy appea...  negative\n",
       "283  and episode really hoping not mention canceled...  negative\n",
       "856  ann margret best job ever done history film ma...  positive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = normalize_text(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    251\n",
       "positive    249\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['sentiment'].isin(['positive','negative'])\n",
    "df = df[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>hugh ed harris hotshot bachelor senator determ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>labor love frame picture perfect grab you shee...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>now like sci fi cartoon however robotboy appea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>and episode really hoping not mention canceled...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>ann margret best job ever done history film ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review  sentiment\n",
       "71   hugh ed harris hotshot bachelor senator determ...          1\n",
       "775  labor love frame picture perfect grab you shee...          1\n",
       "416  now like sci fi cartoon however robotboy appea...          0\n",
       "283  and episode really hoping not mention canceled...          0\n",
       "856  ann margret best job ever done history film ma...          1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['sentiment'].map({'positive':1, 'negative':0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(max_features=100)\n",
    "X = vectorizer.fit_transform(df['review'])\n",
    "y = df['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Accessing as Sonalikasingh17\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Accessing as Sonalikasingh17\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"Sonalikasingh17/Capstone-Project\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Initialized MLflow to track repo \u001b[32m\"Sonalikasingh17/Capstone-Project\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository Sonalikasingh17/Capstone-Project initialized!\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Repository Sonalikasingh17/Capstone-Project initialized!\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/86908e2b6fa0407b9cf71036aac76a22', creation_time=1760072677372, experiment_id='0', last_update_time=1760072677372, lifecycle_stage='active', name='Logistic Regression Baseline', tags={}>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dagshub\n",
    "\n",
    "mlflow.set_tracking_uri('https://dagshub.com/Sonalikasingh17/Capstone-Project.mlflow')\n",
    "dagshub.init(repo_owner='Sonalikasingh17', repo_name='Capstone-Project', mlflow=True)\n",
    "\n",
    "# mlflow.set_experiment(\"Logistic Regression Baseline\")\n",
    "mlflow.set_experiment(\"Logistic Regression Baseline\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 11:38:09,954 - INFO - Starting MLflow run...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-10 11:38:11,762 - INFO - Logging preprocessing parameters...\n",
      "2025-10-10 11:38:12,850 - INFO - Initializing Logistic Regression model...\n",
      "2025-10-10 11:38:12,850 - INFO - Fitting the model...\n",
      "2025-10-10 11:38:12,879 - INFO - Model training complete.\n",
      "2025-10-10 11:38:12,879 - INFO - Logging model parameters...\n",
      "2025-10-10 11:38:13,247 - INFO - Making predictions...\n",
      "2025-10-10 11:38:13,247 - INFO - Calculating evaluation metrics...\n",
      "2025-10-10 11:38:13,256 - INFO - Logging evaluation metrics...\n",
      "2025-10-10 11:38:17,762 - INFO - Saving and logging the model...\n",
      "2025-10-10 11:38:19,891 - INFO - Model saved and logged successfully.\n",
      "2025-10-10 11:38:19,891 - INFO - Model training and logging completed in 8.13 seconds.\n",
      "2025-10-10 11:38:19,891 - INFO - Executing Jupyter Notebook. This may take a while...\n",
      "2025-10-10 11:38:21,223 - INFO - Notebook execution and logging complete.\n",
      "2025-10-10 11:38:21,227 - INFO - Accuracy: 0.7100\n",
      "2025-10-10 11:38:21,227 - INFO - Precision: 0.7500\n",
      "2025-10-10 11:38:21,227 - INFO - Recall: 0.6471\n",
      "2025-10-10 11:38:21,227 - INFO - F1 Score: 0.6947\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏃 View run useful-dog-108 at: https://dagshub.com/Sonalikasingh17/Capstone-Project.mlflow/#/experiments/0/runs/bdc70487e5034fd28162505a4382a849\n",
      "🧪 View experiment at: https://dagshub.com/Sonalikasingh17/Capstone-Project.mlflow/#/experiments/0\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import logging\n",
    "import os\n",
    "import time\n",
    "import joblib\n",
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_code_cell\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# ==============================\n",
    "# Configure logging\n",
    "# ==============================\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "logging.info(\"Starting MLflow run...\")\n",
    "\n",
    "# ==============================\n",
    "# Start MLflow Run\n",
    "# ==============================\n",
    "\n",
    "with mlflow.start_run():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    try:\n",
    "        # ==============================\n",
    "        # Data Loading & Preprocessing\n",
    "        # ==============================\n",
    "\n",
    "        logging.info(\"Logging preprocessing parameters...\")\n",
    "        mlflow.log_param(\"vectorizer\", \"Bag of Words\")\n",
    "        mlflow.log_param(\"num_features\", 50)\n",
    "        mlflow.log_param(\"test_size\", 0.2)\n",
    "\n",
    "        # ==============================\n",
    "        # Model Training\n",
    "        # ==============================\n",
    "\n",
    "        logging.info(\"Initializing Logistic Regression model...\")\n",
    "        model = LogisticRegression(max_iter=1000)  # Increase max_iter to prevent non-convergence issues\n",
    "\n",
    "        logging.info(\"Fitting the model...\")\n",
    "        model.fit(X_train, y_train)\n",
    "        logging.info(\"Model training complete.\")\n",
    "\n",
    "        logging.info(\"Logging model parameters...\")\n",
    "        mlflow.log_param(\"model\", \"Logistic Regression\")\n",
    "\n",
    "\n",
    "        # ==============================\n",
    "        # Model Evaluation\n",
    "        # ==============================\n",
    "\n",
    "        logging.info(\"Making predictions...\")\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        logging.info(\"Calculating evaluation metrics...\")\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision = precision_score(y_test, y_pred)\n",
    "        recall = recall_score(y_test, y_pred)\n",
    "        f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "        logging.info(\"Logging evaluation metrics...\")\n",
    "        mlflow.log_metric(\"accuracy\", accuracy)\n",
    "        mlflow.log_metric(\"precision\", precision)\n",
    "        mlflow.log_metric(\"recall\", recall)\n",
    "        mlflow.log_metric(\"f1_score\", f1)\n",
    "\n",
    "        # ==============================\n",
    "        # Save & Log Model\n",
    "        # ==============================\n",
    "\n",
    "        # Save model locally in pickle format\n",
    "        # mlflow.sklearn.log_model(model, \"model\")\n",
    "        logging.info(\"Saving and logging the model...\")\n",
    "        model_path = os.path.abspath(\"logistic_regression_model.pkl\")\n",
    "        joblib.dump(model, model_path)\n",
    "\n",
    "        # Log it as an artifact\n",
    "        mlflow.log_artifact(model_path)\n",
    "        logging.info(\"Model saved and logged successfully.\")\n",
    "    \n",
    "        # ==============================\n",
    "        # Log execution time\n",
    "        # ==============================\n",
    "        end_time = time.time()\n",
    "        logging.info(f\"Model training and logging completed in {end_time - start_time:.2f} seconds.\")\n",
    "\n",
    "        # Save and log the notebook\n",
    "        notebook_path = \"exp1.ipynb\"\n",
    "        logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        os.system(f\"jupyter nbconvert --to notebook --execute --inplace {notebook_path}\")\n",
    "        mlflow.log_artifact(notebook_path)\n",
    "\n",
    "        logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        \n",
    "        # # ============================== \n",
    "        # # Create & Log Notebook\n",
    "        # # ==============================\n",
    "        # notebook_path = \"exp1_baseline_model.ipynb\"\n",
    "        # abs_notebook_path = os.path.abspath(notebook_path)\n",
    "\n",
    "        # if not os.path.exists(abs_notebook_path):\n",
    "        #     logging.info(f\"Notebook '{notebook_path}' not found. Creating a new one...\")\n",
    "        #     nb = new_notebook(\n",
    "        #         cells=[\n",
    "        #             new_code_cell(\n",
    "        #                 \"\"\"# Experiment 1: Baseline Logistic Regression Model\n",
    "        #                                     import joblib\n",
    "        #                                     print(\"Notebook auto-generated during MLflow run.\")\n",
    "        #                                     model = joblib.load(\"logistic_regression_model.pkl\")\n",
    "        #                                     print(\"Loaded model:\", model)\"\"\"\n",
    "        #             )\n",
    "        #         ]\n",
    "        #     )\n",
    "        #     with open(abs_notebook_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        #         nbformat.write(nb, f)\n",
    "        #     logging.info(\"Notebook created successfully.\")\n",
    "\n",
    "        # # Execute and log the notebook\n",
    "        # logging.info(\"Executing Jupyter Notebook. This may take a while...\")\n",
    "        # os.system(f\"jupyter nbconvert --to notebook --execute --inplace {abs_notebook_path}\")\n",
    "        # mlflow.log_artifact(abs_notebook_path)\n",
    "        # logging.info(\"Notebook execution and logging complete.\")\n",
    "\n",
    "        # ==============================\n",
    "        # Print Metrics\n",
    "        # ==============================\n",
    "    \n",
    "        logging.info(f\"Accuracy: {accuracy:.4f}\")\n",
    "        logging.info(f\"Precision: {precision:.4f}\")\n",
    "        logging.info(f\"Recall: {recall:.4f}\")\n",
    "        logging.info(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An error occurred: {e}\", exc_info=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops_proj1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
